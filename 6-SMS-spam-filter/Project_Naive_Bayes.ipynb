{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spam Filter with the Naive Bayes Algorithm\n",
    "In this project, we build a spam filter for SMS messages.\n",
    "In order to classify messages as spam or non-spam, the high-level algorithm:\n",
    "1. learns how humans classify messages;\n",
    "2. uses that human knowledge to estimate probabilities that new messages are either spam or non-spam;\n",
    "3. classifies a new message using these probability values.\n",
    "\n",
    "We will use a **multinomial Naive Bayes algorithm** and work with a dataset of 5'572 SMS messages that have already been classified by humans. This dataset can be downloaded from the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `SMSSpamCollection` into a Pandas DataFrame using the tab delimiter (`\\t`). Since the dataset does not have a header row, we use the `header=None` option. Moreover, we use the `names=['Label', 'SMS']` parameter to name the columns as Label and SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MS: Read the data into a Pandas DataFrame\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep = \"\\t\", header = None,\n",
    "                 names=['Label', 'SMS'])\n",
    "\n",
    "df.head() # print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 5572 rows (as announced above) and 2 columns.\n",
    "\n",
    "Let's find out the percentages of spam and non-spam (aka \"ham\") messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of spam messages: 13.41\n",
      "% of ham messages:  86.59\n"
     ]
    }
   ],
   "source": [
    "percent_spam = (df[df['Label']=='spam'].shape[0]/df.shape[0])*100\n",
    "percent_ham = (df[df['Label']=='ham'].shape[0]/df.shape[0])*100\n",
    "print('% of spam messages:', round(percent_spam, 2))\n",
    "print('% of ham messages: ', round(percent_ham, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Test Set\n",
    "Before creating the spam filter, let's think and design the test. To test the spam filter, we split the dataset into two categories:\n",
    "- a **training set**, which we use to train the algorithm how to classify messages;\n",
    "- a **test set**, which we use to test how good the spam filter is in classifying new messages.\n",
    "\n",
    "#### 1. Randomize the entire dataset\n",
    "Before splitting the dataset, we randomize the entire dataset to ensure that spam and ham messages are spread properly throughout the dataset. The parameter `frac=1` ensures that the entire dataset is randomized, while `random_state=1` makes sure that the results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       Yep, by the pretty sculpture\n",
       "4028   ham      Yes, princess. Are you going to make me moan?\n",
       "958    ham                         Welp apparently he retired\n",
       "4642   ham                                            Havent.\n",
       "4674   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split the randomized dataset into a training and a test set\n",
    "We choose a 80% - 20% split, in order to train the algorithm on as much data as possible, but still having enough data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_rows = df.shape[0]\n",
    "nb_rows_train_set = round(nb_rows * .80)\n",
    "train_df = df.iloc[0:nb_rows_train_set].copy()\n",
    "test_df = df.iloc[nb_rows_train_set:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of spam messages in the training set: 13.46\n",
      "% of ham messages in the training set:  86.54\n",
      "% of spam messages in the test set: 13.2\n",
      "% of ham messages in the test set:  86.8\n"
     ]
    }
   ],
   "source": [
    "train_percent_spam = (train_df[train_df['Label']=='spam'].shape[0]/train_df.shape[0])*100\n",
    "train_percent_ham = (train_df[train_df['Label']=='ham'].shape[0]/train_df.shape[0])*100\n",
    "print('% of spam messages in the training set:', round(train_percent_spam, 2))\n",
    "print('% of ham messages in the training set: ', round(train_percent_ham, 2))\n",
    "test_percent_spam = (test_df[test_df['Label']=='spam'].shape[0]/test_df.shape[0])*100\n",
    "test_percent_ham = (test_df[test_df['Label']=='ham'].shape[0]/test_df.shape[0])*100\n",
    "print('% of spam messages in the test set:', round(test_percent_spam, 2))\n",
    "print('% of ham messages in the test set: ', round(test_percent_ham, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentages are similar to those we calculated for the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Letter Case and Punctuaction\n",
    "$ \\displaystyle P(Spam\\mid w_1, w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Spam), $\n",
    "\n",
    "where we compute the conditional probabilities with an additive smoothing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\displaystyle P(w_{i} \\mid Spam) = \\frac{N_{w_{i}\\mid Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{\\text{vocabulary}}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $ N_{w_{i}\\mid Spam} $ is the number of times the word $ w_{i} $ occurs in spam messages. $ N_{Spam} $ is the total number of words in spam messages. $ N_{\\text{vocabulary}} $ is the total number of words in the vocabulary. $ \\alpha = 1 $ is the smoothing parameter.\n",
    "\n",
    "We first need to perform some transformation of the data. We replace the `SMS` column by a series of new columns, where each column corresponds to a unique word from the vocabulary.\n",
    "\n",
    "- All words in the vocabulary are in lower case.\n",
    "- Punctuation is not taken into account.\n",
    "\n",
    "In the following, for each message, we remove all the punctuation, transform every letter in every word to lower case, and split the string at the space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_message(message):\n",
    "    # MS: We use the regex '\\W' to detect any character that is not\n",
    "    #     from a-z, A-Z, or 0-9.\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    # MS: For each message, we transform every letter in every word\n",
    "    #     to lower case, and split the string at the space character.\n",
    "    message = message.lower().split()\n",
    "    # print(message)\n",
    "    return(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['SMS'] = train_df['SMS'].apply(clean_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Vocabulary\n",
    "Let's now create a **vocabulary**, i.e., a list with all of the _unique_ words that occur in the messages of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15541', 'ymca', 'parade', 'gail', 'remain', 'poboxox36504w45wq', 'customersqueries', 'greece', 'may', '14tcr']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sms in train_df['SMS']:\n",
    "    # MS: For each message in the 'SMS' column...\n",
    "    for word in sms:\n",
    "        # ... we append each word to the vocabulary list:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# MS: We transform the vocabulary list into a set.\n",
    "#     This removes the duplicates from the vocabulary list.\n",
    "#     Then we transorm the vocabulary set back into a list.\n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "# MS: Print the first 10 words in the vocabulary.\n",
    "print(vocabulary[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Final Training Set\n",
    "We will bring our training set to a format where each column represents a unique word in our vocabulary, showing the frequency of that word in a given message.\n",
    "\n",
    "We first build a **dictionary** that we will then convert to a Pandas DataFrame. This dictionary will have as _keys_ the unique words from the vocabulary we created above, and for each key it will have as a _value_ a list of length of the training, where each element represents the number of times the key (i.e., the word) appears in the current message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0]*nb_rows_train_set for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train_df['SMS']):\n",
    "    # MS: 'index' is the index of the sms in the dataframe train_df,\n",
    "    #     and it is used to access the entries of the list related\n",
    "    #     to each word in the dictionary 'word_counts_per_sms'.\n",
    "    for word in sms:\n",
    "        # For the message corresponding to 'index',\n",
    "        # increment the counter for the current word by 1.\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We transform word_counts_per_sms into Pandas DataFrame and concatenate it with the train_df DataFrame we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms_df = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>frens</th>\n",
       "      <th>frequently</th>\n",
       "      <th>fresh</th>\n",
       "      <th>freshers</th>\n",
       "      <th>fret</th>\n",
       "      <th>fri</th>\n",
       "      <th>friday</th>\n",
       "      <th>fridge</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   french  frens  frequently  fresh  freshers  fret  fri  friday  fridge  \\\n",
       "0       0      0           0      0         0     0    0       0       0   \n",
       "1       0      0           0      0         0     0    0       0       0   \n",
       "2       0      0           0      0         0     0    0       0       0   \n",
       "3       0      0           0      0         0     0    0       0       0   \n",
       "4       0      0           0      0         0     0    0       0       0   \n",
       "5       0      0           0      0         0     0    0       0       0   \n",
       "6       0      0           0      0         0     0    0       0       0   \n",
       "7       0      0           0      0         0     0    0       0       0   \n",
       "8       0      0           0      0         0     0    0       0       0   \n",
       "9       0      0           0      0         0     0    0       0       0   \n",
       "\n",
       "   friend  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms_df.iloc[0:10, 3000:3010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_clean = pd.concat([train_df, word_counts_per_sms_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a portion of the dataframe so created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS    0   00  000\n",
       "0   ham  [go, until, jurong, point, crazy, available, o...  0.0  0.0  0.0\n",
       "1   ham                     [ok, lar, joking, wif, u, oni]  0.0  0.0  0.0\n",
       "2   NaN                                                NaN  0.0  0.0  0.0\n",
       "3   ham  [u, dun, say, so, early, hor, u, c, already, t...  0.0  0.0  0.0\n",
       "4   ham  [nah, i, don, t, think, he, goes, to, usf, he,...  0.0  0.0  0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean.iloc[0:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculating Constants\n",
    "To be able to classify new messages, the Naive Bayes algorithm needs to know the values of the probabilities appearing in the following equations:\n",
    "$ \\displaystyle P(Spam\\mid w_1, w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Spam), $\n",
    "\n",
    "$ \\displaystyle P(Ham\\mid w_1, w_2, \\ldots, w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Ham), $\n",
    "\n",
    "where\n",
    "\n",
    "$ \\displaystyle P(w_{i} \\mid Spam) = \\frac{N_{w_{i}\\mid Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{\\text{vocabulary}}}, $\n",
    "\n",
    "$ \\displaystyle P(w_{i} \\mid Ham) = \\frac{N_{w_{i}\\mid Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{\\text{vocabulary}}}. $\n",
    "\n",
    "$ N_{Spam} $ is equal to the number of words in all the spam messages — it's not equal to the number of spam messages, and it's not equal to the total number of unique words in spam messages. Analogously for $ N_{Ham} $. We will use Laplace smoothing and set $ \\alpha = 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15190\n",
      "57237\n",
      "7783\n"
     ]
    }
   ],
   "source": [
    "spam_messages = train_df_clean[train_df_clean['Label']=='spam']\n",
    "ham_messages = train_df_clean[train_df_clean['Label']=='ham']\n",
    "\n",
    "# MS: We calculate P(Spam) and P(Ham).\n",
    "p_spam = len(spam_messages)/len(train_df_clean)\n",
    "p_ham = len(ham_messages)/len(train_df_clean)\n",
    "\n",
    "# N_Spam and N_Ham.\n",
    "# We apply the function 'len' to each row of the 'SMS' column\n",
    "# of the spam_messages dataframe to compute the number of words\n",
    "# in each message, then we use np.sum() to get the total number\n",
    "# of words in all the spam messages.\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = np.sum(n_words_per_spam_message)\n",
    "print(n_spam)\n",
    "\n",
    "# Analogously for the ham_messages dataframe.\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = np.sum(n_words_per_ham_message)\n",
    "print(n_ham)\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "print(n_vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculating Parameters\n",
    "All the values computed in the previous section are constant values, in the sense that they do not depend on each message or each individual word in a message. On the contrary, $ P(w_{i}\\mid Spam) $ and $ P(w_{i}\\mid Ham) $ vary depending on individual words:\n",
    "\n",
    "$ \\displaystyle P(w_{i} \\mid Spam) = \\frac{N_{w_{i}\\mid Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{\\text{vocabulary}}}, $\n",
    "\n",
    "$ \\displaystyle P(w_{i} \\mid Ham) = \\frac{N_{w_{i}\\mid Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{\\text{vocabulary}}}. $\n",
    "\n",
    "We emphasize that $ P(w_{i}\\mid Spam) $ only depends on the training set, and as long as we do not change the training set, $ P(w_{i}\\mid Spam) $ stays constant. _This means that we can use our training set to calculate the probability for each word in our vocabulary._\n",
    "\n",
    "We have 7'783 words in our vocabulary, so we have to compute a total of 15'566 probabilities, since for each word we have to compute both $ P(w_{i}\\mid Spam) $ and $ P(w_{i}\\mid Ham) $.\n",
    "\n",
    "_Rephrase all of this part: In more technical language, the probability values that P(wi|Spam) and P(wi|Ham) will take are called parameters.\n",
    "The fact that we calculate so many values before even beginning the classification of new messages makes the Naive Bayes algorithm very fast (especially compared to other algorithms). When a new message comes in, most of the needed computations are already done, which enables the algorithm to almost instantly classify the new message.\n",
    "If we didn't calculate all these values beforehand, then all these calculations would need to be done every time a new message comes in. _\n",
    "\n",
    "We recall that $ P(w_{i}\\mid Spam) $ and $ P(w_{i}\\mid Ham) $ are key parts of the equations that we will use to classify new messages:\n",
    "\n",
    "$ \\displaystyle P(Spam\\mid w_1, w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Spam), $\n",
    "\n",
    "$ \\displaystyle P(Ham\\mid w_1, w_2, \\ldots, w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Ham). $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We initialize two dictionaries, in which we will store the parameters\n",
    "# for P(wi|Spam) and P(wi|Ham), respectively.\n",
    "dictionary_p_wi_spam = dict( zip(vocabulary, [0]*len(vocabulary)) )\n",
    "dictionary_p_wi_ham = dict( zip(vocabulary, [0]*len(vocabulary)) )\n",
    "\n",
    "# We isolate the spam and the ham messages in the training set into\n",
    "# two different DataFrames.\n",
    "spam_train_df = train_df_clean[train_df_clean['Label']=='spam']\n",
    "ham_train_df = train_df_clean[train_df_clean['Label']=='ham']\n",
    "\n",
    "# Now we iterate over the vocabulary and for each word we calculate\n",
    "# P(wi|Spam) and P(wi|Ham).\n",
    "\n",
    "for wi in vocabulary:\n",
    "    n_wi_spam = np.sum(spam_train_df[wi])\n",
    "    dictionary_p_wi_spam[wi] = (n_wi_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    \n",
    "    n_wi_ham = np.sum(ham_train_df[wi])\n",
    "    dictionary_p_wi_ham[wi] = (n_wi_ham + alpha) / (n_ham + alpha * n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Classifying a New Message\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. \n",
    "\n",
    "$ \\displaystyle P(Spam\\mid w_1, w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Spam), $\n",
    "\n",
    "$ \\displaystyle P(Ham\\mid w_1, w_2, \\ldots, w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n} P(w_{i}\\mid Ham). $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message).lower().split()\n",
    "\n",
    "    # Initializations\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Now we perform the calculationds corresponding to the\n",
    "    # formulas above.\n",
    "    for word in message:\n",
    "        if word in dictionary_p_wi_spam:\n",
    "            p_spam_given_message *= dictionary_p_wi_spam[word]\n",
    "        if word in dictionary_p_wi_ham:\n",
    "            p_ham_given_message *= dictionary_p_wi_ham[word]\n",
    "            \n",
    "        # If the word is not present in any of the two dictionaries,\n",
    "        # then don't do anything. \n",
    "        # We ignore words that are not part of the vocabulary.\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Use the classify() function to classify two new messages. You can use any messages you want, but we suggest that one message is obviously spam, and the other is obviously ham. For instance, you can use these two messages:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "sms2 = \"Sounds good, Tom, then see u there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 4.1578268320785084e-29\n",
      "P(Ham|message): 1.284446514392249e-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(sms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4449942502228983e-24\n",
      "P(Ham|message): 4.287484325865619e-22\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(sms2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Measuring the Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message).lower().split()\n",
    "    \n",
    "    # Initializations\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Now we perform the calculationds corresponding to the\n",
    "    # formulas above.\n",
    "    for word in message:\n",
    "        if word in dictionary_p_wi_spam:\n",
    "            p_spam_given_message *= dictionary_p_wi_spam[word]\n",
    "        if word in dictionary_p_wi_ham:\n",
    "            p_ham_given_message *= dictionary_p_wi_ham[word]\n",
    "            \n",
    "        # If the word is not present in any of the two dictionaries,\n",
    "        # then don't do anything. \n",
    "        # We ignore words that are not part of the vocabulary.\n",
    "\n",
    "    # print('P(Spam|message):', p_spam_given_message)\n",
    "    # print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        # print('Label: Ham')\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        # print('Label: Spam')\n",
    "        return 'spam'\n",
    "    else:\n",
    "        # print('Equal proabilities, have a human classify this!')\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "3424  spam  Had your mobile 10 mths? Update to latest Oran...       ham\n",
       "1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['predicted'] = test_df['SMS'].apply(classify_test_set)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages. To make the measurement, we'll use accuracy as a metric:\n",
    "\n",
    "$ \\displaystyle \\text{Accuracy} = \\frac{\\text{number of correctly classified messages}}{\\text{total number of classified messages}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 965\n",
      "Incorrect: 149\n",
      "Accuracy: 86.62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_df) # number of messages in the test set\n",
    "\n",
    "#iterate through each row of dataframe\n",
    "for index, row in test_df.iterrows():\n",
    "    if row['predicted'] == row['Label']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', round(correct/total*100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
